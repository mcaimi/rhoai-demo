{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ba74fe-4d24-455b-b64c-38bc1f846a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/app-root/lib/python3.9/site-packages (24.3.1)\n",
      "Requirement already satisfied: boto3 in /opt/app-root/lib/python3.9/site-packages (1.34.162)\n",
      "Requirement already satisfied: vllm in /opt/app-root/lib/python3.9/site-packages (0.6.4.post1)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.162 in /opt/app-root/lib/python3.9/site-packages (from boto3) (1.34.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/app-root/lib/python3.9/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/app-root/lib/python3.9/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (from vllm) (5.9.8)\n",
      "Requirement already satisfied: sentencepiece in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/app-root/lib/python3.9/site-packages (from vllm) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/app-root/lib/python3.9/site-packages (from vllm) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib/python3.9/site-packages (from vllm) (4.66.5)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/app-root/lib/python3.9/site-packages (from vllm) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.45.2 in /opt/app-root/lib/python3.9/site-packages (from vllm) (4.46.3)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.20.3)\n",
      "Requirement already satisfied: protobuf in /opt/app-root/lib/python3.9/site-packages (from vllm) (4.25.4)\n",
      "Requirement already satisfied: aiohttp in /opt/app-root/lib/python3.9/site-packages (from vllm) (3.10.5)\n",
      "Requirement already satisfied: openai>=1.45.0 in /opt/app-root/lib/python3.9/site-packages (from vllm) (1.55.0)\n",
      "Requirement already satisfied: uvicorn[standard] in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.32.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /opt/app-root/lib/python3.9/site-packages (from vllm) (2.10.1)\n",
      "Requirement already satisfied: pillow in /opt/app-root/lib/python3.9/site-packages (from vllm) (10.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.20.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /opt/app-root/lib/python3.9/site-packages (from vllm) (7.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.7.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.10.9)\n",
      "Requirement already satisfied: outlines<0.1,>=0.0.43 in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.0.46)\n",
      "Requirement already satisfied: typing-extensions>=4.10 in /opt/app-root/lib/python3.9/site-packages (from vllm) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /opt/app-root/lib/python3.9/site-packages (from vllm) (3.15.4)\n",
      "Requirement already satisfied: partial-json-parser in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.2.1.1.post4)\n",
      "Requirement already satisfied: pyzmq in /opt/app-root/lib/python3.9/site-packages (from vllm) (26.2.0)\n",
      "Requirement already satisfied: msgspec in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.18.6)\n",
      "Requirement already satisfied: gguf==0.10.0 in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.10.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/app-root/lib/python3.9/site-packages (from vllm) (8.4.0)\n",
      "Requirement already satisfied: mistral-common>=1.5.0 in /opt/app-root/lib/python3.9/site-packages (from mistral-common[opencv]>=1.5.0->vllm) (1.5.1)\n",
      "Requirement already satisfied: pyyaml in /opt/app-root/lib/python3.9/site-packages (from vllm) (6.0.2)\n",
      "Requirement already satisfied: einops in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.8.0)\n",
      "Requirement already satisfied: compressed-tensors==0.8.0 in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.8.0)\n",
      "Requirement already satisfied: ray>=2.9 in /opt/app-root/lib/python3.9/site-packages (from vllm) (2.23.0)\n",
      "Requirement already satisfied: nvidia-ml-py>=12.560.30 in /opt/app-root/lib/python3.9/site-packages (from vllm) (12.560.30)\n",
      "Requirement already satisfied: torch==2.5.1 in /opt/app-root/lib/python3.9/site-packages (from vllm) (2.5.1)\n",
      "Requirement already satisfied: torchvision==0.20.1 in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.20.1)\n",
      "Requirement already satisfied: xformers==0.0.28.post3 in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.0.28.post3)\n",
      "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /opt/app-root/lib/python3.9/site-packages (from vllm) (0.115.5)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/app-root/lib/python3.9/site-packages (from torch==2.5.1->vllm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib/python3.9/site-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib/python3.9/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/app-root/lib/python3.9/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (1.26.19)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/app-root/lib/python3.9/site-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm) (0.41.3)\n",
      "Requirement already satisfied: interegular>=0.3.2 in /opt/app-root/lib/python3.9/site-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (0.3.3)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib/python3.9/site-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (24.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /opt/app-root/lib/python3.9/site-packages (from mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm) (4.23.0)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /opt/app-root/lib/python3.9/site-packages (from mistral-common[opencv]>=1.5.0->vllm) (4.10.0.84)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib/python3.9/site-packages (from openai>=1.45.0->vllm) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/app-root/lib/python3.9/site-packages (from openai>=1.45.0->vllm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib/python3.9/site-packages (from openai>=1.45.0->vllm) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/app-root/lib/python3.9/site-packages (from openai>=1.45.0->vllm) (0.7.1)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib/python3.9/site-packages (from openai>=1.45.0->vllm) (1.3.1)\n",
      "Requirement already satisfied: lark in /opt/app-root/lib/python3.9/site-packages (from outlines<0.1,>=0.0.43->vllm) (1.2.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/app-root/lib/python3.9/site-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/app-root/lib/python3.9/site-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.0)\n",
      "Requirement already satisfied: diskcache in /opt/app-root/lib/python3.9/site-packages (from outlines<0.1,>=0.0.43->vllm) (5.6.3)\n",
      "Requirement already satisfied: numba in /opt/app-root/lib/python3.9/site-packages (from outlines<0.1,>=0.0.43->vllm) (0.60.0)\n",
      "Requirement already satisfied: referencing in /opt/app-root/lib/python3.9/site-packages (from outlines<0.1,>=0.0.43->vllm) (0.35.1)\n",
      "Requirement already satisfied: datasets in /opt/app-root/lib/python3.9/site-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.0)\n",
      "Requirement already satisfied: pycountry in /opt/app-root/lib/python3.9/site-packages (from outlines<0.1,>=0.0.43->vllm) (24.6.1)\n",
      "Requirement already satisfied: pyairports in /opt/app-root/lib/python3.9/site-packages (from outlines<0.1,>=0.0.43->vllm) (2.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/app-root/lib/python3.9/site-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/app-root/lib/python3.9/site-packages (from pydantic>=2.9->vllm) (2.27.1)\n",
      "Requirement already satisfied: click>=7.0 in /opt/app-root/lib/python3.9/site-packages (from ray>=2.9->vllm) (8.1.7)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/app-root/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.0.8)\n",
      "Requirement already satisfied: aiosignal in /opt/app-root/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /opt/app-root/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.26.0->vllm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.26.0->vllm) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.26.0->vllm) (2024.7.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/app-root/lib/python3.9/site-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/app-root/lib/python3.9/site-packages (from tokenizers>=0.19.1->vllm) (0.26.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/app-root/lib/python3.9/site-packages (from transformers>=4.45.2->vllm) (0.4.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->vllm) (2.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->vllm) (24.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->vllm) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->vllm) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->vllm) (4.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/app-root/lib/python3.9/site-packages (from importlib-metadata->vllm) (3.20.1)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]->vllm) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]->vllm) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]->vllm) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]->vllm) (1.0.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/app-root/lib/python3.9/site-packages (from uvicorn[standard]->vllm) (14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/app-root/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai>=1.45.0->vllm) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai>=1.45.0->vllm) (1.0.7)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/app-root/lib/python3.9/site-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/app-root/lib/python3.9/site-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm) (0.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.162->boto3) (1.16.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/app-root/lib/python3.9/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/app-root/lib/python3.9/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.9/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib/python3.9/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/app-root/lib/python3.9/site-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.70.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch==2.5.1->vllm) (2.1.5)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/app-root/lib/python3.9/site-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.43.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install boto3 vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eacfa8b-18c7-46b2-87b2-419973492f1f",
   "metadata": {},
   "source": [
    "Import required libraries:\n",
    "\n",
    "- vLLM is used to perform local offline inference\n",
    "- from vLLM we import the local LLM class that is used to load an HuggingFace transformer checkpoint\n",
    "- also import the SamplingParams class that is used to customize inference parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fecedd1-564d-4b07-8761-72eb43793174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, yaml\n",
    "try:\n",
    "    import boto3\n",
    "    from vllm import LLM, SamplingParams\n",
    "except Exception as e:\n",
    "    print(f\"Caught exception: {e}\")\n",
    "    sys.exit(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c2129-604c-4689-acd1-92a256cd98f5",
   "metadata": {},
   "source": [
    "Load parameters from the configuration yaml file\n",
    "\n",
    "We'll need\n",
    "\n",
    "- the checkpoint path\n",
    "- the inference parameter configuration\n",
    "- checkpoint file names\n",
    "- S3 repo data connection pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7979002-05b5-4fa5-9603-44000a663a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dictionary class that holds parameters\n",
    "# load values from a yaml file\n",
    "class Parameters(object):\n",
    "    def __init__(self, data: dict):\n",
    "        if type(data) != dict:\n",
    "            raise TypeError(f\"Parameters: expected 'dict', got {type(data)}.\")\n",
    "        else:\n",
    "            self.data = data\n",
    "\n",
    "        for k in self.data.keys():\n",
    "            if type(self.data.get(k)) != dict:\n",
    "                self.__setattr__(k, self.data.get(k))\n",
    "            else:\n",
    "                self.__setattr__(k, Parameters(self.data.get(k)))\n",
    "\n",
    "# load parameters file and read values into a dictionary class\n",
    "try:\n",
    "    with open(\"parameters.yaml\") as parms:\n",
    "        config_parms = yaml.safe_load(parms)\n",
    "    creds = Parameters(config_parms)\n",
    "except yaml.YAMLError as e:\n",
    "    print(f\"Error loading YAML file: {e}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Caught exception: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e20a5-e21b-4283-a135-0bb0e17e1701",
   "metadata": {},
   "source": [
    "Download the required model checkpoint locally from the relevant S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6251655-1455-4c2c-ae9a-ce47f5d2e86b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing S3 endpoint http://minio.ic-shared-minio.svc.cluster.local:9000 with ACCESS_KEY buTNe4R2AVxYK4RDCOEy...\n",
      "File model-00001-of-00003.safetensors already downloaded.\n",
      "File model-00002-of-00003.safetensors already downloaded.\n",
      "File model-00003-of-00003.safetensors already downloaded.\n",
      "File model.safetensors.index.json already downloaded.\n",
      "File generation_config.json already downloaded.\n",
      "File tokenizer_config.json already downloaded.\n",
      "File config.json already downloaded.\n",
      "File added_tokens.json already downloaded.\n",
      "File tokenizer.json already downloaded.\n",
      "File tokenizer.model already downloaded.\n",
      "File tokenizer_config.json already downloaded.\n",
      "File special_tokens_map.json already downloaded.\n",
      "File added_tokens.json already downloaded.\n"
     ]
    }
   ],
   "source": [
    "# shamelessly stolen from aws docs :D\n",
    "class ProgressPercentage(object):\n",
    "    def __init__(self, filename):\n",
    "        self._filename = filename\n",
    "        self._size = float(os.path.getsize(filename))\n",
    "        self._seen_so_far = 0\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def __call__(self, bytes_amount):\n",
    "        # To simplify, assume this is hooked up to a single filename\n",
    "        with self._lock:\n",
    "            self._seen_so_far += bytes_amount\n",
    "            percentage = (self._seen_so_far / self._size) * 100\n",
    "            sys.stdout.write(\n",
    "                \"\\r%s  %s / %s  (%.2f%%)\" % (\n",
    "                    self._filename, self._seen_so_far, self._size,\n",
    "                    percentage))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "# download model from s3 if needed\n",
    "try:\n",
    "    # connect to MinIO and prepare buckets\n",
    "    print(f\"Accessing S3 endpoint {creds.params.url} with ACCESS_KEY {creds.params.accessKey}...\")\n",
    "\n",
    "    # instantiate connection\n",
    "    minio_api = boto3.client(\"s3\", endpoint_url=creds.params.url, aws_access_key_id=creds.params.accessKey, aws_secret_access_key=creds.params.secretKey)\n",
    "except Exception as e:\n",
    "    print(f\"Caught exception: {e}\")\n",
    "\n",
    "# create folder to store training data\n",
    "mistral_models_path = \"/\".join((creds.huggingface.modelsPath, creds.huggingface.modelName))\n",
    "os.makedirs(mistral_models_path, exist_ok=True)\n",
    "\n",
    "# get list of data files\n",
    "try:\n",
    "    for file in creds.huggingface.filenames:\n",
    "        if not os.path.exists(\"/\".join((mistral_models_path, file))):\n",
    "            print(f\"Downloading file: {file} to {mistral_models_path}\")\n",
    "            minio_api.download_file(creds.huggingface.modelBucket, file,\n",
    "                                        \"/\".join((mistral_models_path, file)))\n",
    "        else:\n",
    "            print(f\"File {file} already downloaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Caught Exception {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3841ed7-73c4-40b7-8ca8-5c941a1bb1d4",
   "metadata": {},
   "source": [
    "Now let's instantiate the model from the downloaded checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5141c3b3-081d-4205-80d2-4f29efd75437",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-25 13:29:06 config.py:1861] Downcasting torch.float32 to torch.float16.\n",
      "INFO 11-25 13:29:06 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 11-25 13:29:06 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='model_checkpoints/ibm-granite/granite-7b-instruct', speculative_config=None, tokenizer='model_checkpoints/ibm-granite/granite-7b-instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=model_checkpoints/ibm-granite/granite-7b-instruct, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n",
      "INFO 11-25 13:29:07 model_runner.py:1072] Starting to load model model_checkpoints/ibm-granite/granite-7b-instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7955e1f7b2af480daa0376e194a3f64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-25 13:30:49 model_runner.py:1077] Loading model weights took 12.5523 GB\n",
      "INFO 11-25 13:30:50 worker.py:232] Memory profiling results: total_gpu_memory=21.98GiB initial_memory_usage=13.09GiB peak_torch_memory=12.91GiB memory_usage_post_profile=13.09GiB non_torch_memory=0.53GiB kv_cache_size=6.34GiB gpu_memory_utilization=0.90\n",
      "INFO 11-25 13:30:50 gpu_executor.py:113] # GPU blocks: 811, # CPU blocks: 512\n",
      "INFO 11-25 13:30:50 gpu_executor.py:117] Maximum concurrency for 4096 tokens per request: 3.17x\n",
      "INFO 11-25 13:30:50 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 11-25 13:30:50 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 11-25 13:31:05 model_runner.py:1518] Graph capturing finished in 15 secs, took 0.06 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# load model and serve via vLLM\n",
    "llm_model = vllm.LLM(model=mistral_models_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f2946-fe41-4766-857f-6c7f8c7c990d",
   "metadata": {},
   "source": [
    "Once we have a model loaded & ready, let's prepare for inference\n",
    "\n",
    "- set up a SamplingParams object set up with correct parameters\n",
    "- perform inference\n",
    "- translate back tokens to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb3a3e48-b177-4a3e-be3b-2b8ba98ef39a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.86s/it, est. speed input: 1.02 toks/s, output: 32.63 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'Tell me about Red Hat Openshift',\n",
      " Generated text: \".2.x and Red Hat OpenShift Container Platform  latest versions.\\n\\nA:\\n\\nRed Hat OpenShift is a containerization platform based on Kubernetes, which allows developers to build, deploy, and manage containerized applications. The latest version of Red Hat OpenShift is OpenShift 4.11, which was released in November 2021.\\n\\nRed Hat OpenShift 4.11 introduces several new features and improvements, including:\\n\\n1. Improved performance and scalability: OpenShift 4.11 includes performance and scalability improvements, such as better memory management and faster container startup times.\\n2. Enhanced security: OpenShift 4.11 includes new security features, such as the ability to securely manage container images using the Secrets Manager and the ability to enable multi-factor authentication (MFA) for cluster administrators.\\n3. Simplified management: OpenShift 4.11 includes simplified management features, such as the ability to automate the rollout of new features and the ability to easily manage containerized applications using the OpenShift CLI (oc) and the OpenShift web console.\\n4. Support for new container runtimes: OpenShift 4.11 includes support for new container runtimes, such as CRI-O and rkt, which provide more flexibility and choice in how containers are run.\\n5. Improved integration with other Red Hat technologies: OpenShift 4.11 includes improved integration with other Red Hat technologies, such as Red Hat Quay, Red Hat Tectonic, and Red Hat Ansible Tower.\\n\\nIf you're interested in learning more about OpenShift 4.11, I would recommend checking out the official OpenShift documentation and resources.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# display responses\n",
    "def response(llm_output: list) -> str:\n",
    "    for o in llm_output:\n",
    "        prompt = r.prompt\n",
    "        gen_text = r.outputs[0].text\n",
    "        print(f\"Prompt: {prompt!r},\\n Generated text: {gen_text!r}\")\n",
    "\n",
    "# prepare parameters\n",
    "sp = SamplingParams(min_tokens=creds.local_inference.min_tokens,\n",
    "                        max_tokens=creds.local_inference.max_tokens,\n",
    "                        temperature=creds.local_inference.temperature)\n",
    "\n",
    "# test inference\n",
    "prompt=\"Tell me about Red Hat Openshift\"\n",
    "responses = llm_model.generate(prompts=prompt, sampling_params=sp)\n",
    "\n",
    "# display responses\n",
    "response(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be7d75-52e2-421f-8f38-0320bd0bfd8f",
   "metadata": {},
   "source": [
    "Finally, free up resources allocated to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd188659-973c-49af-86b7-20e0c541b171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# free resources\n",
    "del llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb84c0-9daf-4f0e-a89d-e272b39b491d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
