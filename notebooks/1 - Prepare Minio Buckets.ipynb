{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5be1cb81-265e-4295-966b-bc31744e24e0",
   "metadata": {},
   "source": [
    "## 1 - Download the required model checkpoint and prepare all required dependencies\n",
    "\n",
    "This notebook serves as an initialization for the RHOAI demo code. Here we will initialize all required components and download the initail Mistral LLM Checkpoint\n",
    "As a pre-requirement step, some info are needed in the parameters.yaml file:\n",
    "\n",
    "* The ACCESS_KEY, SECRET_KEY and S3_ENDPOINT of the deplopyed MinIO instance\n",
    "* the HuggingFace API_KEY that can browse and download from public repos (this is needed to download the initail checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12cb822-e6c3-4c79-98b2-1da29dddbfed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U pip\n",
    "!pip install boto3 huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d5162b-91ab-4c28-899b-e9b8d8572c8b",
   "metadata": {},
   "source": [
    "After installing some required libraries (mainly boto3 to interface the notebook with the S3 storage and the hugging face library), import all required libraries and modules in the notebook for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b97c2-44d7-4120-97f4-739ca2321b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os, yaml, sys, threading\n",
    "from pathlib import Path\n",
    "try:\n",
    "    import boto3\n",
    "    from boto3.s3.transfer import TransferConfig\n",
    "    from botocore.exceptions import ClientError\n",
    "    import huggingface_hub as hf\n",
    "except Exception as e:\n",
    "    print(f\"Exception during library import: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64beacd7-3b61-4740-8b49-a4ec7c14e203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dictionary class that holds parameters\n",
    "# load values from a yaml file\n",
    "class Parameters(object):\n",
    "    def __init__(self, data: dict):\n",
    "        if type(data) != dict:\n",
    "            raise TypeError(f\"Parameters: expected 'dict', got {type(data)}.\")\n",
    "        else:\n",
    "            self.data = data\n",
    "\n",
    "        for k in self.data.keys():\n",
    "            if type(self.data.get(k)) != dict:\n",
    "                self.__setattr__(k, self.data.get(k))\n",
    "            else:\n",
    "                self.__setattr__(k, Parameters(self.data.get(k)))\n",
    "\n",
    "# shamelessly stolen from aws docs :D\n",
    "class ProgressPercentage(object):\n",
    "    def __init__(self, filename):\n",
    "        self._filename = filename\n",
    "        self._size = float(os.path.getsize(filename))\n",
    "        self._seen_so_far = 0\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def __call__(self, bytes_amount):\n",
    "        # To simplify, assume this is hooked up to a single filename\n",
    "        with self._lock:\n",
    "            self._seen_so_far += bytes_amount\n",
    "            percentage = (self._seen_so_far / self._size) * 100\n",
    "            sys.stdout.write(\n",
    "                \"\\r%s  %s / %s  (%.2f%%)\" % (\n",
    "                    self._filename, self._seen_so_far, self._size,\n",
    "                    percentage))\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c265c-9d88-47da-a1a8-826cf75a1e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load parameters file and read values into a dictionary class\n",
    "try:\n",
    "    with open(\"parameters.yaml\") as parms:\n",
    "        config_parms = yaml.safe_load(parms)\n",
    "    creds = Parameters(config_parms)\n",
    "except yaml.YAMLError as e:\n",
    "    print(f\"Error loading YAML file: {e}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Caught exception: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0d0b72-f4f6-4cac-aea1-ae8d0657f050",
   "metadata": {},
   "source": [
    "Using the configration written in the parameters file, create all required buckets in the S3 storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba110732-bd02-4c3f-94e4-97044f510f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# connect to MinIO and prepare buckets\n",
    "print(f\"Accessing S3 endpoint {creds.params.url} with ACCESS_KEY {creds.params.accessKey}...\")\n",
    "\n",
    "# instantiate connection\n",
    "minio_api = boto3.client(\"s3\", endpoint_url=creds.params.url, aws_access_key_id=creds.params.accessKey, aws_secret_access_key=creds.params.secretKey)\n",
    "\n",
    "# Create the models bucket\n",
    "available_buckets = [buckets[\"Name\"] for buckets in minio_api.list_buckets()[\"Buckets\"]]\n",
    "for bckname in creds.s3.bucket_list:\n",
    "    print(f\"-> Creating bucket {bckname}...\")\n",
    "    if bckname not in available_buckets:\n",
    "        try:\n",
    "            minio_api.create_bucket(Bucket=bckname)\n",
    "        except Exception as e:\n",
    "            print(f\"Failure during bucket creation due to this error: {e}\")\n",
    "    else:\n",
    "        print(f\"--> Bucket ({bckname}) Already Exists. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8116cb75-34b3-4193-94b7-e9988857006b",
   "metadata": {},
   "source": [
    "Then download the Mistral 7B checkpoint from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5aff6-71e4-4ffb-a1cf-94de3d58401d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download model checkpoint from HuggingFace repositories\n",
    "os.environ[\"HF_HOME\"] = creds.huggingface.hfHomePath\n",
    "remote_model_objects = {}\n",
    "mistral_models_path = \"/\".join((creds.huggingface.modelsPath, creds.huggingface.modelName))\n",
    "os.makedirs(mistral_models_path, exist_ok=True)\n",
    "\n",
    "print(f\"Downloading model checkpoint: {creds.huggingface.modelName}\")\n",
    "for name in creds.huggingface.filenames:\n",
    "    model_path = hf.snapshot_download(repo_id=creds.huggingface.modelName, \n",
    "                                        allow_patterns=creds.huggingface.filenames, \n",
    "                                        revision=\"main\", \n",
    "                                        token=creds.huggingface.apiToken,\n",
    "                                        local_dir=mistral_models_path)\n",
    "    print(f\"Downloaded model checkpoint {model_path}\")\n",
    "    for n in creds.huggingface.filenames:\n",
    "        remote_model_objects[\"/\".join((model_path, n))] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f05d6b9-f0f4-49ca-949d-7e02e8b93e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checks whether a file exists in a remote bucket\n",
    "def check_exists(s3api, bucket, filename):\n",
    "    rsp = s3api.list_objects_v2(Bucket=bucket, Prefix=filename)\n",
    "    try:\n",
    "        contents = rsp.get(\"Contents\")\n",
    "        files = [ obj.get(\"Key\") for obj in contents ]\n",
    "        if filename in files:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf9c74d-ee33-4fd7-8930-f14a26b1d698",
   "metadata": {},
   "source": [
    "Finally upload the checkpoint to the local S3 bucket we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8970f461-2967-4b59-9da2-9969cb3aad76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the desired multipart threshold value (5GB)\n",
    "GB = 1024 ** 3\n",
    "transfer_config = TransferConfig(multipart_threshold = 5*GB, use_threads=False)\n",
    "\n",
    "try:\n",
    "    for k in remote_model_objects.keys():\n",
    "        if not check_exists(minio_api, creds.huggingface.modelBucket, remote_model_objects[k]):\n",
    "            print(f\"Uploading {remote_model_objects[k]} to MinIO bucket {creds.huggingface.modelBucket}\")\n",
    "            minio_api.upload_file(k, creds.huggingface.modelBucket,\n",
    "                                    remote_model_objects[k],\n",
    "                                    Callback=ProgressPercentage(k),\n",
    "                                    Config=transfer_config)\n",
    "            print(\"---\")\n",
    "        else:\n",
    "            print(f\"File {k} already exists in {creds.huggingface.modelBucket}\")\n",
    "except ClientError as e:\n",
    "    print(f\"S3 Exception: {e.response['Error']['Code']}, trace: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Caught exception: {e}\")\n",
    "\n",
    "print(\"Upload Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe5f35-4d85-4f49-8b56-40f43ea8a96e",
   "metadata": {},
   "source": [
    "Last step: Upload all required training data we will use to populate the Vector DB that will be the backed for the RAG Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd1d3a-3d4e-4d74-a430-2d9a362768f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload training dataset (data for vectorization)\n",
    "data_path = Path(\"training_data\")\n",
    "data_types = [\"**/*.pdf\", \"**/*.txt\"]\n",
    "\n",
    "for ftype in data_types:\n",
    "    for file in list(data_path.glob(ftype)):\n",
    "        try:\n",
    "            if not check_exists(minio_api, creds.training_data.trainingDataBucket, os.path.basename(file)):\n",
    "                print(f\"Uploading {file} to MinIO bucket {creds.training_data.trainingDataBucket}\")\n",
    "                minio_api.upload_file(file,\n",
    "                                      creds.training_data.trainingDataBucket,\n",
    "                                      os.path.basename(file),\n",
    "                                      Callback=ProgressPercentage(file),\n",
    "                                      Config=transfer_config)\n",
    "                print(\"---\")\n",
    "            else:\n",
    "                print(f\"File {file} already exists in {creds.training_data.trainingDataBucket}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Caught exception: {e}\")\n",
    "\n",
    "print(f\"Upload Complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
